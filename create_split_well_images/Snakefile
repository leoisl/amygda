# ======================================================
# Config files
# ======================================================
configfile: "config.yaml"

import glob
from pathlib import Path
import pandas as pd
import shutil

def get_plate_name_to_plate_path(plate_dir):
    all_plate_images_as_str = glob.glob(f"{plate_dir}/**/*-raw.png", recursive=True)
    all_plate_images_paths = [Path(plate_image) for plate_image in all_plate_images_as_str]
    return {path.with_suffix('').name: str(path.resolve()) for path in all_plate_images_paths}

plate_name_to_plate_path = get_plate_name_to_plate_path(config["plate_images"])
# print(f"plate_name_to_plate_path = {plate_name_to_plate_path}")

output_dir = Path(config["output_dir"])

all_split_wells_dirs = []
all_split_filtered_wells_dirs = []
all_translation_csvs = []
for plate_name in plate_name_to_plate_path.keys():
    all_split_wells_dirs.append(str(output_dir / f"{plate_name}_split"))
    all_split_filtered_wells_dirs.append(str(output_dir / f"{plate_name}_split_filtered"))
    all_translation_csvs.append(str(output_dir / f"{plate_name}.translation.csv"))


rule all:
    input:
         split_wells_dir = output_dir / "all/all_split_wells_concatenated",
         translation_csv =  output_dir / "all/all_plates.translation.csv"


rule split_well_images:
    input:
         raw_input = lambda wildcards: plate_name_to_plate_path[wildcards.plate_name]
    output:
         split_wells_dir = directory(output_dir / "{plate_name}_split"),
         split_filtered_wells_dir = directory(output_dir / "{plate_name}_split_filtered"),
         translation_csv =  output_dir / "{plate_name}.translation.csv"
    threads: 1
    log: "logs/split_wells_image/{plate_name}.log"
    resources:
        mem_mb = 2000
    shell:
         "python create_split_wells_image.py --plate_image {input.raw_input} --well_dir {output.split_wells_dir} "
         "--translation_csv {output.translation_csv}"


rule concatenate_well_images:
    input:
         all_split_wells_dirs = all_split_wells_dirs,
         all_translation_csvs = all_translation_csvs
    output:
         split_wells_dir = directory(output_dir / "all/all_split_wells_concatenated"),
         translation_csv =  output_dir / "all/all_plates.translation.csv"
    threads: 1
    log: "logs/concatenate_well_images.log"
    resources:
        mem_mb = 8000
    run:
        split_wells_dir_path = Path(output.split_wells_dir)
        split_wells_dir_path.mkdir(parents=True, exist_ok=True)
        dict_csv = {
            "original_plate_path_file": [],
            "anonymous_plate_path_dir_well_split": []
        }

        index_anonymous_plate = 0
        for translation_csv_filename in input.all_translation_csvs:
            translation_csv = pd.read_csv(translation_csv_filename)
            split_went_well = len(translation_csv) > 0
            if split_went_well:
                original_plate_path_file = translation_csv["original_plate_path_file"][0]
                anonymous_plate_path_dir_well_split = translation_csv["anonymous_plate_path_dir_well_split"][0]
                new_anonymous_plate_path_dir_well_split = split_wells_dir_path.resolve()/f"{index_anonymous_plate}"
                shutil.copytree(anonymous_plate_path_dir_well_split, new_anonymous_plate_path_dir_well_split)
                shutil.copytree(str(anonymous_plate_path_dir_well_split)+"_filtered",
                                str(new_anonymous_plate_path_dir_well_split)+"_filtered")

                dict_csv["original_plate_path_file"].append(str(original_plate_path_file))
                dict_csv["anonymous_plate_path_dir_well_split"].append(str(new_anonymous_plate_path_dir_well_split))

                index_anonymous_plate += 1

        df = pd.DataFrame.from_dict(dict_csv)
        df["anonymous_plate_path_dir_well_split_filtered"] = df["anonymous_plate_path_dir_well_split"]+"_filtered"
        df.to_csv(output.translation_csv, index=False)
